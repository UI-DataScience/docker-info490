{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download sample text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#!/usr/bin/env bash\n",
    "# A Bash Shell Script to delete the Hadoop diorectory if it exists, afterwhich\n",
    "# make a new Hadoop directory\n",
    "\n",
    "# Our directory name\n",
    "DIR=$HOME/hadoop\n",
    "\n",
    "# Delete if exists\n",
    "if [ -d \"$DIR\" ]; then\n",
    "    rm -rf \"$DIR\"\n",
    "fi\n",
    "\n",
    "# Now make the directory\n",
    "mkdir \"$DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-04-06 08:50:31--  https://raw.githubusercontent.com/UI-DataScience/info490-sp16/master/orientation/syllabus.md\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 23.235.44.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|23.235.44.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15079 (15K) [text/plain]\n",
      "Saving to: ‘/home/data_scientist/hadoop/syllabus.md’\n",
      "\n",
      "100%[======================================>] 15,079      --.-K/s   in 0s      \n",
      "\n",
      "2016-04-06 08:50:35 (380 MB/s) - ‘/home/data_scientist/hadoop/syllabus.md’ saved [15079/15079]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grab a book to process\n",
    "!wget https://raw.githubusercontent.com/UI-DataScience/info490-sp16/master/orientation/syllabus.md -O $HOME/hadoop/syllabus.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put: `syllabus.md': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!$HADOOP_PREFIX/bin/hdfs dfs -put $HOME/hadoop/syllabus.md syllabus.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wordcount.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile wordcount.pig\n",
    "A = load 'syllabus.md' as (line:chararray);\n",
    "B = foreach A generate TOKENIZE(line) as tokens;\n",
    "C = foreach B generate flatten(tokens) as words;\n",
    "D = group C by words;\n",
    "E = foreach D generate group, COUNT(C);\n",
    "F = order E by $1;\n",
    "dump F;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Pig in cluster mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/04/06 08:50:37 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n",
      "16/04/06 08:50:37 INFO pig.ExecTypeProvider: Trying ExecType : MAPREDUCE\n",
      "16/04/06 08:50:37 INFO pig.ExecTypeProvider: Picked MAPREDUCE as the ExecType\n",
      "2016-04-06 08:50:37,824 [main] INFO  org.apache.pig.Main - Apache Pig version 0.15.0 (r1682971) compiled Jun 01 2015, 11:44:35\n",
      "2016-04-06 08:50:37,824 [main] INFO  org.apache.pig.Main - Logging error messages to: /home/data_scientist/pig_1459932637823.log\n",
      "2016-04-06 08:50:38,274 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /home/data_scientist/.pigbootup not found\n",
      "2016-04-06 08:50:38,346 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2016-04-06 08:50:38,346 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2016-04-06 08:50:38,346 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: hdfs://119b35b22a37:9000\n",
      "2016-04-06 08:50:39,274 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2016-04-06 08:50:39,435 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: GROUP_BY,ORDER_BY\n",
      "2016-04-06 08:50:39,458 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2016-04-06 08:50:39,460 [main] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n",
      "2016-04-06 08:50:39,481 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2016-04-06 08:50:39,567 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n",
      "2016-04-06 08:50:39,588 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil - Choosing to move algebraic foreach to combiner\n",
      "2016-04-06 08:50:39,603 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR - Using Secondary Key Optimization for MapReduce node scope-25\n",
      "2016-04-06 08:50:39,610 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 3\n",
      "2016-04-06 08:50:39,610 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 3\n",
      "2016-04-06 08:50:39,634 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2016-04-06 08:50:39,657 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:50:39,818 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2016-04-06 08:50:39,823 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2016-04-06 08:50:39,823 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2016-04-06 08:50:39,823 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2016-04-06 08:50:39,824 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2016-04-06 08:50:39,825 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2016-04-06 08:50:39,844 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=15079\n",
      "2016-04-06 08:50:39,844 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2016-04-06 08:50:39,844 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2016-04-06 08:50:39,844 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - This job cannot be converted run in-process\n",
      "2016-04-06 08:50:40,044 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/usr/local/pig-0.15.0/pig-0.15.0-core-h2.jar to DistributedCache through /tmp/temp-1397699840/tmp-476382747/pig-0.15.0-core-h2.jar\n",
      "2016-04-06 08:50:40,070 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/usr/local/pig-0.15.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1397699840/tmp1541420622/automaton-1.11-8.jar\n",
      "2016-04-06 08:50:40,089 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/usr/local/pig-0.15.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1397699840/tmp1126342836/antlr-runtime-3.4.jar\n",
      "2016-04-06 08:50:40,121 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/usr/local/pig-0.15.0/lib/joda-time-2.5.jar to DistributedCache through /tmp/temp-1397699840/tmp1287731581/joda-time-2.5.jar\n",
      "2016-04-06 08:50:40,160 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2016-04-06 08:50:40,166 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
      "2016-04-06 08:50:40,166 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
      "2016-04-06 08:50:40,166 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Setting key [pig.schematuple.classes] with classes to deserialize []\n",
      "2016-04-06 08:50:40,234 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2016-04-06 08:50:40,235 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2016-04-06 08:50:40,239 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:50:40,255 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2016-04-06 08:50:40,452 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2016-04-06 08:50:40,499 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
      "2016-04-06 08:50:40,499 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2016-04-06 08:50:40,520 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2016-04-06 08:50:40,570 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2016-04-06 08:50:40,671 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1459932351054_0004\n",
      "2016-04-06 08:50:40,769 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2016-04-06 08:50:40,835 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1459932351054_0004\n",
      "2016-04-06 08:50:40,861 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://119b35b22a37:8088/proxy/application_1459932351054_0004/\n",
      "2016-04-06 08:50:40,861 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_1459932351054_0004\n",
      "2016-04-06 08:50:40,862 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases A,B,C,D,E\n",
      "2016-04-06 08:50:40,862 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: A[1,4],B[-1,-1],C[3,4],E[5,4],D[4,4] C: E[5,4],D[4,4] R: E[5,4]\n",
      "2016-04-06 08:50:40,867 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete\n",
      "2016-04-06 08:50:40,868 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_1459932351054_0004]\n",
      "2016-04-06 08:50:49,910 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 16% complete\n",
      "2016-04-06 08:50:49,910 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_1459932351054_0004]\n",
      "2016-04-06 08:50:55,918 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 33% complete\n",
      "2016-04-06 08:50:55,918 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_1459932351054_0004]\n",
      "2016-04-06 08:51:00,925 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:00,933 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2016-04-06 08:51:01,163 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:01,170 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2016-04-06 08:51:01,229 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:01,235 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2016-04-06 08:51:01,272 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2016-04-06 08:51:01,273 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2016-04-06 08:51:01,274 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2016-04-06 08:51:01,274 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2016-04-06 08:51:01,286 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=13375\n",
      "2016-04-06 08:51:01,287 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2016-04-06 08:51:01,287 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - This job cannot be converted run in-process\n",
      "2016-04-06 08:51:01,338 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/usr/local/pig-0.15.0/pig-0.15.0-core-h2.jar to DistributedCache through /tmp/temp-1397699840/tmp-1427668456/pig-0.15.0-core-h2.jar\n",
      "2016-04-06 08:51:01,359 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/usr/local/pig-0.15.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1397699840/tmp75521350/automaton-1.11-8.jar\n",
      "2016-04-06 08:51:01,379 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/usr/local/pig-0.15.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1397699840/tmp-442474034/antlr-runtime-3.4.jar\n",
      "2016-04-06 08:51:01,396 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/usr/local/pig-0.15.0/lib/joda-time-2.5.jar to DistributedCache through /tmp/temp-1397699840/tmp-15632277/joda-time-2.5.jar\n",
      "2016-04-06 08:51:01,406 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2016-04-06 08:51:01,407 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
      "2016-04-06 08:51:01,407 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
      "2016-04-06 08:51:01,407 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Setting key [pig.schematuple.classes] with classes to deserialize []\n",
      "2016-04-06 08:51:01,428 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2016-04-06 08:51:01,430 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:01,436 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2016-04-06 08:51:01,444 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2016-04-06 08:51:01,468 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
      "2016-04-06 08:51:01,469 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2016-04-06 08:51:01,469 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2016-04-06 08:51:01,503 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2016-04-06 08:51:01,529 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1459932351054_0005\n",
      "2016-04-06 08:51:01,533 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2016-04-06 08:51:01,554 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1459932351054_0005\n",
      "2016-04-06 08:51:01,557 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://119b35b22a37:8088/proxy/application_1459932351054_0005/\n",
      "2016-04-06 08:51:01,929 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_1459932351054_0005\n",
      "2016-04-06 08:51:01,929 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases F\n",
      "2016-04-06 08:51:01,929 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: F[6,4] C:  R: \n",
      "2016-04-06 08:51:10,949 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 50% complete\n",
      "2016-04-06 08:51:10,950 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_1459932351054_0005]\n",
      "2016-04-06 08:51:16,456 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 66% complete\n",
      "2016-04-06 08:51:16,456 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_1459932351054_0005]\n",
      "2016-04-06 08:51:21,964 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:21,970 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2016-04-06 08:51:22,087 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:22,095 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2016-04-06 08:51:22,135 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:22,138 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2016-04-06 08:51:22,166 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2016-04-06 08:51:22,166 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2016-04-06 08:51:22,167 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2016-04-06 08:51:22,167 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2016-04-06 08:51:22,167 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - This job cannot be converted run in-process\n",
      "2016-04-06 08:51:22,223 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/usr/local/pig-0.15.0/pig-0.15.0-core-h2.jar to DistributedCache through /tmp/temp-1397699840/tmp-2129680416/pig-0.15.0-core-h2.jar\n",
      "2016-04-06 08:51:22,241 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/usr/local/pig-0.15.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-1397699840/tmp225714184/automaton-1.11-8.jar\n",
      "2016-04-06 08:51:22,256 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/usr/local/pig-0.15.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-1397699840/tmp432052311/antlr-runtime-3.4.jar\n",
      "2016-04-06 08:51:22,275 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/usr/local/pig-0.15.0/lib/joda-time-2.5.jar to DistributedCache through /tmp/temp-1397699840/tmp1198135896/joda-time-2.5.jar\n",
      "2016-04-06 08:51:22,281 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2016-04-06 08:51:22,282 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
      "2016-04-06 08:51:22,282 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
      "2016-04-06 08:51:22,282 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Setting key [pig.schematuple.classes] with classes to deserialize []\n",
      "2016-04-06 08:51:22,307 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2016-04-06 08:51:22,309 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:22,321 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2016-04-06 08:51:22,334 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2016-04-06 08:51:22,356 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
      "2016-04-06 08:51:22,356 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2016-04-06 08:51:22,356 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2016-04-06 08:51:22,401 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2016-04-06 08:51:22,436 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1459932351054_0006\n",
      "2016-04-06 08:51:22,438 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2016-04-06 08:51:22,659 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1459932351054_0006\n",
      "2016-04-06 08:51:22,661 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://119b35b22a37:8088/proxy/application_1459932351054_0006/\n",
      "2016-04-06 08:51:22,808 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_1459932351054_0006\n",
      "2016-04-06 08:51:22,808 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases F\n",
      "2016-04-06 08:51:22,808 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: F[6,4] C:  R: \n",
      "2016-04-06 08:51:31,853 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 83% complete\n",
      "2016-04-06 08:51:31,853 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_1459932351054_0006]\n",
      "2016-04-06 08:51:36,860 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_1459932351054_0006]\n",
      "2016-04-06 08:51:37,865 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:37,871 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2016-04-06 08:51:37,941 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:37,949 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2016-04-06 08:51:37,985 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:37,993 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2016-04-06 08:51:38,021 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n",
      "2016-04-06 08:51:38,041 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n",
      "\n",
      "HadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n",
      "2.7.2\t0.15.0\tdata_scientist\t2016-04-06 08:50:39\t2016-04-06 08:51:38\tGROUP_BY,ORDER_BY\n",
      "\n",
      "Success!\n",
      "\n",
      "Job Stats (time in seconds):\n",
      "JobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\n",
      "job_1459932351054_0004\t1\t1\t2\t2\t2\t2\t3\t3\t3\t3\tA,B,C,D,E\tGROUP_BY,COMBINER\t\n",
      "job_1459932351054_0005\t1\t1\t2\t2\t2\t2\t2\t2\t2\t2\tF\tSAMPLER\t\n",
      "job_1459932351054_0006\t1\t1\t2\t2\t2\t2\t2\t2\t2\t2\tF\tORDER_BY\thdfs://119b35b22a37:9000/tmp/temp-1397699840/tmp-427188205,\n",
      "\n",
      "Input(s):\n",
      "Successfully read 338 records (15462 bytes) from: \"hdfs://119b35b22a37:9000/user/data_scientist/syllabus.md\"\n",
      "\n",
      "Output(s):\n",
      "Successfully stored 877 records (13375 bytes) in: \"hdfs://119b35b22a37:9000/tmp/temp-1397699840/tmp-427188205\"\n",
      "\n",
      "Counters:\n",
      "Total records written : 877\n",
      "Total bytes written : 13375\n",
      "Spillable Memory Manager spill count : 0\n",
      "Total bags proactively spilled: 0\n",
      "Total records proactively spilled: 0\n",
      "\n",
      "Job DAG:\n",
      "job_1459932351054_0004\t->\tjob_1459932351054_0005,\n",
      "job_1459932351054_0005\t->\tjob_1459932351054_0006,\n",
      "job_1459932351054_0006\n",
      "\n",
      "\n",
      "2016-04-06 08:51:38,042 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:38,044 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2016-04-06 08:51:38,074 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:38,078 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2016-04-06 08:51:38,107 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:38,111 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2016-04-06 08:51:38,147 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:38,150 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2016-04-06 08:51:38,177 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:38,185 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2016-04-06 08:51:38,210 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:38,213 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2016-04-06 08:51:38,245 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:38,247 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2016-04-06 08:51:38,285 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:38,288 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2016-04-06 08:51:38,326 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2016-04-06 08:51:38,330 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2016-04-06 08:51:38,353 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
      "2016-04-06 08:51:38,355 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - fs.default.name is deprecated. Instead, use fs.defaultFS\n",
      "2016-04-06 08:51:38,356 [main] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n",
      "2016-04-06 08:51:38,362 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1\n",
      "2016-04-06 08:51:38,362 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "(,0)\n",
      "(!,1)\n",
      "(http://www.admin.illinois.edu/policy/code/article_1/a1_1-401.html,1)\n",
      "(https://learn.illinois.edu/mod/forum/view.php?id=1325062,1)\n",
      "(https://learn.illinois.edu/mod/forum/view.php?id=1325059,1)\n",
      "(https://gitter.im/UI-DataScience/info490-sp16,1)\n",
      "(|----------|-----------|----------------|,1)\n",
      "(|-----------|-----|-----|-----|,1)\n",
      "(notebooks/intro2ip.ipynb,1)\n",
      "(|--------|---------|,1)\n",
      "(internet-accessible,1)\n",
      "(|Percentage|Letter,1)\n",
      "(Assessments|60|14,1)\n",
      "(emails/questions,1)\n",
      "(contextualized,1)\n",
      "(undergraduate,1)\n",
      "(subscription.,1)\n",
      "(project-based,1)\n",
      "(progressively,1)\n",
      "(pre-requisite,1)\n",
      "(insignificant,1)\n",
      "(falsification,1)\n",
      "(documentation,1)\n",
      "(demonstrating,1)\n",
      "(corresponding,1)\n",
      "(computational,1)\n",
      "(collaborative,1)\n",
      "(approximately,1)\n",
      "(`index.ipynb`,1)\n",
      "([Announcement,1)\n",
      "(Quiz|70|1|70|,1)\n",
      "(Quizzes|70|14,1)\n",
      "(Probabilistic,1)\n",
      "(Prerequisites,1)\n",
      "(Communication,1)\n",
      "(|Orientation,1)\n",
      "(|Assignments,1)\n",
      "(unsupervised,1)\n",
      "(supplemental,1)\n",
      "(requirements,1)\n",
      "(recommended.,1)\n",
      "(programming;,1)\n",
      "(instructions,1)\n",
      "(department's,1)\n",
      "(demonstrated,1)\n",
      "(Videos|20|16,1)\n",
      "(University's,1)\n",
      "(Reductions__,1)\n",
      "(Occurrences|,1)\n",
      "(Distribution,1)\n",
      "(|Assignment,1)\n",
      "(|98-100|A+|,1)\n",
      "(|----|----|,1)\n",
      "(unsubscribe,1)\n",
      "(statistical,1)\n",
      "(simplifying,1)\n",
      "(responsible,1)\n",
      "(repository.,1)\n",
      "(programming,1)\n",
      "(proficiency,1)\n",
      "(partnership,1)\n",
      "(orientation,1)\n",
      "(interacting,1)\n",
      "(infraction.,1)\n",
      "(information,1)\n",
      "(dimensional,1)\n",
      "(departments,1)\n",
      "(communicate,1)\n",
      "(cloud-based,1)\n",
      "(classmates!,1)\n",
      "(application,1)\n",
      "(University.,1)\n",
      "(Programming,1)\n",
      "(Furthermore,1)\n",
      "(Foundations,1)\n",
      "(|Pre-Class,1)\n",
      "(|90-92|A-|,1)\n",
      "(|88-90|B+|,1)\n",
      "(|80-82|B-|,1)\n",
      "(|78-80|C+|,1)\n",
      "(|70-72|C-|,1)\n",
      "(|68-70|D+|,1)\n",
      "(|60-62|D-|,1)\n",
      "(understand,1)\n",
      "(tentative.,1)\n",
      "(supplement,1)\n",
      "(supervised,1)\n",
      "(summarizes,1)\n",
      "(submission,1)\n",
      "(statically,1)\n",
      "(simplicity,1)\n",
      "(robustness,1)\n",
      "(questions.,1)\n",
      "(plus/minus,1)\n",
      "(plagiarism,1)\n",
      "(particular,1)\n",
      "(objectives,1)\n",
      "(necessary.,1)\n",
      "(imperative,1)\n",
      "(finalized.,1)\n",
      "(especially,1)\n",
      "(documents.,1)\n",
      "(documented,1)\n",
      "(dishonesty,1)\n",
      "(discretion,1)\n",
      "(directions,1)\n",
      "(determined,1)\n",
      "(completion,1)\n",
      "(completing,1)\n",
      "(completely,1)\n",
      "(clustering,1)\n",
      "(classmates,1)\n",
      "(assistant.,1)\n",
      "(alteration,1)\n",
      "(advantages,1)\n",
      "(additional,1)\n",
      "(accessible,1)\n",
      "(Reductions,1)\n",
      "(Integrity],1)\n",
      "(Instructor,1)\n",
      "(Guidelines,1)\n",
      "(Forum][af],1)\n",
      "(Dockerized,1)\n",
      "(Discussing,1)\n",
      "(Computing|,1)\n",
      "(Activities,1)\n",
      "(|92-98|A|,1)\n",
      "(|82-88|B|,1)\n",
      "(|72-78|C|,1)\n",
      "(|62-68|D|,1)\n",
      "(wondering,1)\n",
      "(textbooks,1)\n",
      "(syllabus.,1)\n",
      "(students.,1)\n",
      "(student's,1)\n",
      "(streaming,1)\n",
      "(severely.,1)\n",
      "(room][gr],1)\n",
      "(reviewing,1)\n",
      "(remaining,1)\n",
      "(real-time,1)\n",
      "(questions,1)\n",
      "(notebooks,1)\n",
      "(notebook.,1)\n",
      "(learning;,1)\n",
      "(exploring,1)\n",
      "(essential,1)\n",
      "(erroneous,1)\n",
      "(enrolled.,1)\n",
      "(encourage,1)\n",
      "(employing,1)\n",
      "(deploying,1)\n",
      "(deadlines,1)\n",
      "(contained,1)\n",
      "(concepts.,1)\n",
      "(carefully,1)\n",
      "(available,1)\n",
      "(automated,1)\n",
      "(attempts.,1)\n",
      "(assistant,1)\n",
      "(answered.,1)\n",
      "(analysis;,1)\n",
      "(analysis.,1)\n",
      "(afternoon,1)\n",
      "(advancing,1)\n",
      "(accepted.,1)\n",
      "(Yourself|,1)\n",
      "(Notebooks,1)\n",
      "(Notebook],1)\n",
      "(Introduce,1)\n",
      "(Integrity,1)\n",
      "(Illinois.,1)\n",
      "(Date/Time,1)\n",
      "(Computing,1)\n",
      "(Completed,1)\n",
      "(Activity:,1)\n",
      "(websites,1)\n",
      "(watched.,1)\n",
      "(uploaded,1)\n",
      "(teaching,1)\n",
      "(semester,1)\n",
      "(schedule,1)\n",
      "(reviewed,1)\n",
      "(requests,1)\n",
      "(repeated,1)\n",
      "(receive.,1)\n",
      "(reasons:,1)\n",
      "(reading.,1)\n",
      "(randomly,1)\n",
      "(punished,1)\n",
      "(provides,1)\n",
      "(provided,1)\n",
      "(problems,1)\n",
      "(possible,1)\n",
      "(offenses,1)\n",
      "(monitors,1)\n",
      "(minimize,1)\n",
      "(majority,1)\n",
      "(instance,1)\n",
      "(indicate,1)\n",
      "(graduate,1)\n",
      "(grading.,1)\n",
      "(forums__,1)\n",
      "(explores,1)\n",
      "(excerpts,1)\n",
      "(entries.,1)\n",
      "(embedded,1)\n",
      "(emailing,1)\n",
      "(dropping,1)\n",
      "(directly,1)\n",
      "(contexts,1)\n",
      "(content.,1)\n",
      "(consider,1)\n",
      "(conclude,1)\n",
      "(complete,1)\n",
      "(colleges,1)\n",
      "(cheating,1)\n",
      "(business,1)\n",
      "(attempts,1)\n",
      "(articles,1)\n",
      "(approval,1)\n",
      "(applying,1)\n",
      "(answers.,1)\n",
      "(actually,1)\n",
      "(__Search,1)\n",
      "([Student,1)\n",
      "([IPython,1)\n",
      "(Syllabus,1)\n",
      "(Students,1)\n",
      "(Specific,1)\n",
      "(Schedule,1)\n",
      "(Samantha,1)\n",
      "(Internet,1)\n",
      "(Deadline,1)\n",
      "(60|1|60|,1)\n",
      "(100–98,1)\n",
      "(|Lesson,1)\n",
      "(|150|13,1)\n",
      "(writing,1)\n",
      "(working,1)\n",
      "(willing,1)\n",
      "(website,1)\n",
      "(version,1)\n",
      "(variety,1)\n",
      "(utilize,1)\n",
      "(updates,1)\n",
      "(typical,1)\n",
      "(topics.,1)\n",
      "(tablets,1)\n",
      "(subject,1)\n",
      "(several,1)\n",
      "(running,1)\n",
      "(review;,1)\n",
      "(review.,1)\n",
      "(resort.,1)\n",
      "(reserve,1)\n",
      "(require,1)\n",
      "(request,1)\n",
      "(related,1)\n",
      "(reduced,1)\n",
      "(reading,1)\n",
      "(provide,1)\n",
      "(process,1)\n",
      "(present,1)\n",
      "(posting,1)\n",
      "(points|,1)\n",
      "(planned,1)\n",
      "(overall,1)\n",
      "(outline,1)\n",
      "(obvious,1)\n",
      "(modules,1)\n",
      "(module.,1)\n",
      "(missing,1)\n",
      "(minimum,1)\n",
      "(limited,1)\n",
      "(lesson.,1)\n",
      "(involve,1)\n",
      "(however,1)\n",
      "(honesty,1)\n",
      "(highest,1)\n",
      "(granted,1)\n",
      "(further,1)\n",
      "(forums.,1)\n",
      "(forums!,1)\n",
      "(faster.,1)\n",
      "(faculty,1)\n",
      "(explain,1)\n",
      "(exactly,1)\n",
      "(efforts,1)\n",
      "(discuss,1)\n",
      "(crashes,1)\n",
      "(covered,1)\n",
      "(context,1)\n",
      "(contact,1)\n",
      "(consist,1)\n",
      "(concept,1)\n",
      "(cluster,1)\n",
      "(clearly,1)\n",
      "(clarify,1)\n",
      "(channel,1)\n",
      "(changes,1)\n",
      "(browser,1)\n",
      "(broader,1)\n",
      "(benefit,1)\n",
      "(average,1)\n",
      "(answers,1)\n",
      "(already,1)\n",
      "(against,1)\n",
      "(__Point,1)\n",
      "([gitter,1)\n",
      "(Thrush.,1)\n",
      "(Serious,1)\n",
      "(Review|,1)\n",
      "(Quizzes,1)\n",
      "(Points|,1)\n",
      "(Outline,1)\n",
      "(Network,1)\n",
      "(Instead,1)\n",
      "(General,1)\n",
      "(Failure,1)\n",
      "(90–92,1)\n",
      "(18-hour,1)\n",
      "(|Below,1)\n",
      "(|1950|,1)\n",
      "(viewed,1)\n",
      "(video.,1)\n",
      "(values,1)\n",
      "(update,1)\n",
      "(twenty,1)\n",
      "(trying,1)\n",
      "(tracks,1)\n",
      "(topics,1)\n",
      "(thirty,1)\n",
      "(tasks.,1)\n",
      "(stores,1)\n",
      "(stifle,1)\n",
      "(stack.,1)\n",
      "(score.,1)\n",
      "(public,1)\n",
      "(please,1)\n",
      "(phones,1)\n",
      "(peers',1)\n",
      "(peer's,1)\n",
      "(obtain,1)\n",
      "(number,1)\n",
      "(normal,1)\n",
      "(module,1)\n",
      "(modern,1)\n",
      "(mining,1)\n",
      "(method,1)\n",
      "(making,1)\n",
      "(lowest,1)\n",
      "(limits,1)\n",
      "(letter,1)\n",
      "(hosted,1)\n",
      "(having,1)\n",
      "(freely,1)\n",
      "(forum.,1)\n",
      "(fellow,1)\n",
      "(faster,1)\n",
      "(expand,1)\n",
      "(except,1)\n",
      "(edited,1)\n",
      "(derive,1)\n",
      "(deemed,1)\n",
      "(corner,1)\n",
      "(change,1)\n",
      "(behind,1)\n",
      "(assess,1)\n",
      "(around,1)\n",
      "(answer,1)\n",
      "(albeit,1)\n",
      "(across,1)\n",
      "(access,1)\n",
      "([qaf]:,1)\n",
      "(Videos,1)\n",
      "(Topics,1)\n",
      "(Social,1)\n",
      "(Sample,1)\n",
      "(Safari,1)\n",
      "(Points,1)\n",
      "(NoSQL|,1)\n",
      "(Models,1)\n",
      "(Linear,1)\n",
      "(Hadoop,1)\n",
      "(Grade|,1)\n",
      "(Github,1)\n",
      "(Format,1)\n",
      "(Credit,1)\n",
      "(|Peer,1)\n",
      "(|980|,1)\n",
      "(|860|,1)\n",
      "(|320|,1)\n",
      "(zero.,1)\n",
      "(would,1)\n",
      "(worth,1)\n",
      "(work.,1)\n",
      "(wiki.,1)\n",
      "(where,1)\n",
      "(upper,1)\n",
      "(tool.,1)\n",
      "(timed,1)\n",
      "(those,1)\n",
      "(tasks,1)\n",
      "(table,1)\n",
      "(smart,1)\n",
      "(sites,1)\n",
      "(site.,1)\n",
      "(quiz.,1)\n",
      "(other,1)\n",
      "(offer,1)\n",
      "(news!,1)\n",
      "(needs,1)\n",
      "(means,1)\n",
      "(major,1)\n",
      "(login,1)\n",
      "(local,1)\n",
      "(least,1)\n",
      "(learn,1)\n",
      "(large,1)\n",
      "(forty,1)\n",
      "(focus,1)\n",
      "(first,1)\n",
      "(file.,1)\n",
      "(field,1)\n",
      "(extra,1)\n",
      "(exams,1)\n",
      "(entry,1)\n",
      "(email,1)\n",
      "(down?,1)\n",
      "(doing,1)\n",
      "(curve,1)\n",
      "(cases,1)\n",
      "(being,1)\n",
      "(added,1)\n",
      "(abide,1)\n",
      "([gr]:,1)\n",
      "([af]:,1)\n",
      "(Weeks,1)\n",
      "(Video,1)\n",
      "(These,1)\n",
      "(Texts,1)\n",
      "(Spark,1)\n",
      "(Scale,1)\n",
      "(Point,1)\n",
      "(Opens,1)\n",
      "(NoSQL,1)\n",
      "(Media,1)\n",
      "(Grade,1)\n",
      "(Goals,1)\n",
      "(Final,1)\n",
      "(Extra,1)\n",
      "(Exams,1)\n",
      "(Every,1)\n",
      "(After,1)\n",
      "(<!--|,1)\n",
      "(60|F|,1)\n",
      "(wiki,1)\n",
      "(when,1)\n",
      "(what,1)\n",
      "(ways,1)\n",
      "(view,1)\n",
      "(used,1)\n",
      "(upon,1)\n",
      "(tool,1)\n",
      "(thus,1)\n",
      "(test,1)\n",
      "(span,1)\n",
      "(some,1)\n",
      "(sole,1)\n",
      "(risk,1)\n",
      "(push,1)\n",
      "(plan,1)\n",
      "(past,1)\n",
      "(pace,1)\n",
      "(own.,1)\n",
      "(next,1)\n",
      "(much,1)\n",
      "(move,1)\n",
      "(miss,1)\n",
      "(loss,1)\n",
      "(load,1)\n",
      "(less,1)\n",
      "(late,1)\n",
      "(know,1)\n",
      "(into,1)\n",
      "(info,1)\n",
      "(idea,1)\n",
      "(i.e.,1)\n",
      "(hour,1)\n",
      "(good,1)\n",
      "(give,1)\n",
      "(form,1)\n",
      "(due.,1)\n",
      "(drop,1)\n",
      "(demo,1)\n",
      "(code,1)\n",
      "(case,1)\n",
      "(best,1)\n",
      "(been,1)\n",
      "(Upon,1)\n",
      "(Thus,1)\n",
      "(Task,1)\n",
      "(Quiz,1)\n",
      "(Part,1)\n",
      "(Late,1)\n",
      "(Item,1)\n",
      "(Deep,1)\n",
      "(Days,1)\n",
      "(Code,1)\n",
      "(Both,1)\n",
      "(Also,1)\n",
      "(<!--,1)\n",
      "(4240,1)\n",
      "(2-14,1)\n",
      "(|||,1)\n",
      "(why,1)\n",
      "(who,1)\n",
      "(web,1)\n",
      "(she,1)\n",
      "(set,1)\n",
      "(see,1)\n",
      "(per,1)\n",
      "(our,1)\n",
      "(nor,1)\n",
      "(its,1)\n",
      "(his,1)\n",
      "(her,1)\n",
      "(ask,1)\n",
      "(add,1)\n",
      "(Web,1)\n",
      "(She,1)\n",
      "(For,1)\n",
      "(FAQ,1)\n",
      "(FAA,1)\n",
      "(Any,1)\n",
      "(All,1)\n",
      "(90%,1)\n",
      "(80%,1)\n",
      "(70%,1)\n",
      "(50%,1)\n",
      "(us,1)\n",
      "(it,1)\n",
      "(am,1)\n",
      "(On,1)\n",
      "(No,1)\n",
      "(Do,1)\n",
      "(CS,1)\n",
      "(At,1)\n",
      "(A-,1)\n",
      "(A+,1)\n",
      "(70,1)\n",
      "(40,1)\n",
      "(4.,1)\n",
      "(3.,1)\n",
      "(24,1)\n",
      "(20,1)\n",
      "(2.,1)\n",
      "(14,1)\n",
      "(13,1)\n",
      "(11,1)\n",
      "(10,1)\n",
      "(1.,1)\n",
      "(A,1)\n",
      "(:,1)\n",
      "(9,1)\n",
      "(6,1)\n",
      "(5,1)\n",
      "(2,1)\n",
      "(1,1)\n",
      "(0,1)\n",
      "(&,1)\n",
      "(assigned,2)\n",
      "(However,2)\n",
      "(submitted,2)\n",
      "(probabilistic,2)\n",
      "(deadline.,2)\n",
      "(different,2)\n",
      "(1:00,2)\n",
      "(within,2)\n",
      "(preferred,2)\n",
      "(practical,2)\n",
      "(note,2)\n",
      "(material.,2)\n",
      "(Review,2)\n",
      "(answered,2)\n",
      "(analysis,2)\n",
      "(advanced,2)\n",
      "(need,2)\n",
      "(academic,2)\n",
      "(Please,2)\n",
      "(text,2)\n",
      "(overview,2)\n",
      "(familiar,2)\n",
      "(than,2)\n",
      "(previous,2)\n",
      "(Mining,2)\n",
      "(them,2)\n",
      "(enrolled,2)\n",
      "(Overview,2)\n",
      "(Notebook,2)\n",
      "(forums,2)\n",
      "(read,2)\n",
      "(many,2)\n",
      "(|Weekly,2)\n",
      "(github,2)\n",
      "(list,2)\n",
      "(any,2)\n",
      "(graded,2)\n",
      "(all,2)\n",
      "(before,2)\n",
      "(readings,2)\n",
      "(communication,2)\n",
      "(through,2)\n",
      "(grades,2)\n",
      "(which,2)\n",
      "(scores.,2)\n",
      "(science,2)\n",
      "(out,2)\n",
      "(respond,2)\n",
      "(help,2)\n",
      "(information.,2)\n",
      "(three,2)\n",
      "(key,2)\n",
      "(these,2)\n",
      "(Unsupervised,2)\n",
      "(designed,2)\n",
      "(run,2)\n",
      "(software,2)\n",
      "(full,2)\n",
      "(taken,2)\n",
      "(solution,2)\n",
      "(still,2)\n",
      "(traditional,2)\n",
      "(submission.,2)\n",
      "(such,2)\n",
      "(five,2)\n",
      "(feel,2)\n",
      "(since,2)\n",
      "(network,2)\n",
      "(score,2)\n",
      "(right,2)\n",
      "(distributed,2)\n",
      "(mastery,2)\n",
      "(machine,2)\n",
      "(demonstrate,2)\n",
      "(located,2)\n",
      "(locally,2)\n",
      "(point,2)\n",
      "(syllabus,2)\n",
      "(assessment.,2)\n",
      "(lessons,2)\n",
      "(peers,2)\n",
      "(Orientation,2)\n",
      "(include,2)\n",
      "(12,2)\n",
      "(Forum][qaf],2)\n",
      "(7,2)\n",
      "(80,2)\n",
      "(Analysis|,2)\n",
      "(either,2)\n",
      "(general,2)\n",
      "(Finally,2)\n",
      "(#,2)\n",
      "(Collected,2)\n",
      "(links,2)\n",
      "(Generally,2)\n",
      "(able,2)\n",
      "(hours,2)\n",
      "(graph,2)\n",
      "(cutoffs,2)\n",
      "(created,2)\n",
      "(grace,2)\n",
      "(courses,2)\n",
      "(work,2)\n",
      "(expected,2)\n",
      "(period,2)\n",
      "(mastered,2)\n",
      "([Q&A,2)\n",
      "(Your,2)\n",
      "(Wiki,2)\n",
      "(-->,2)\n",
      "(two,2)\n",
      "(Text,2)\n",
      "(computing.,2)\n",
      "(result,2)\n",
      "(aspects,2)\n",
      "(30,2)\n",
      "(assessment,2)\n",
      "(build,2)\n",
      "(books,2)\n",
      "(activities,2)\n",
      "(ensure,2)\n",
      "(University,2)\n",
      "(Supervised,2)\n",
      "(up,2)\n",
      "(Mediaspace,2)\n",
      "(Unlike,2)\n",
      "(allow,2)\n",
      "(after,2)\n",
      "(automatic,2)\n",
      "(so,2)\n",
      "(Assignment,2)\n",
      "(4,2)\n",
      "(Moodle.,2)\n",
      "(Cloud,2)\n",
      "(automatically,3)\n",
      "(12:00,3)\n",
      "(reduction,3)\n",
      "(server,3)\n",
      "(Note:,3)\n",
      "(---,3)\n",
      "(student,3)\n",
      "(no,3)\n",
      "(15,3)\n",
      "(during,3)\n",
      "(490:,3)\n",
      "(important,3)\n",
      "(approach,3)\n",
      "(get,3)\n",
      "(section,3)\n",
      "(how,3)\n",
      "(Assessments,3)\n",
      "(online,3)\n",
      "(addition,3)\n",
      "(video,3)\n",
      "(using,3)\n",
      "(To,3)\n",
      "(prior,3)\n",
      "(required,3)\n",
      "(own,3)\n",
      "(learning,3)\n",
      "(Lessons,3)\n",
      "(Note,3)\n",
      "(assignments.,3)\n",
      "(Saturday,3)\n",
      "(Lesson,3)\n",
      "(part,3)\n",
      "(Science,3)\n",
      "(collected,3)\n",
      "(more,3)\n",
      "(Illinois,3)\n",
      "(deadline,3)\n",
      "(contain,3)\n",
      "(Academic,3)\n",
      "(via,3)\n",
      "(Friday,3)\n",
      "(search,3)\n",
      "(3,3)\n",
      "(Docker,3)\n",
      "(assessments,3)\n",
      "(Course,3)\n",
      "(problem,3)\n",
      "(150,3)\n",
      "(instructional,3)\n",
      "(viewing,3)\n",
      "(should,3)\n",
      "(last,3)\n",
      "(INFO,3)\n",
      "(well,3)\n",
      "(multiple,3)\n",
      "(Data,3)\n",
      "(cloud,3)\n",
      "(As,3)\n",
      "(Total,3)\n",
      "(container,3)\n",
      "(If,3)\n",
      "(There,3)\n",
      "(content,4)\n",
      "(Thursday,4)\n",
      "(Readings,4)\n",
      "(Advanced,4)\n",
      "(In,4)\n",
      "(server.,4)\n",
      "(8,4)\n",
      "(receive,4)\n",
      "(there,4)\n",
      "(staff,4)\n",
      "(even,4)\n",
      "(maximum,4)\n",
      "(Assignments,4)\n",
      "(grading,4)\n",
      "(course.,4)\n",
      "(forum,4)\n",
      "(Tuesday,4)\n",
      "(JupyterHub,4)\n",
      "(Assessment,4)\n",
      "(IPython,4)\n",
      "(Grading,4)\n",
      "(videos,4)\n",
      "(submit,4)\n",
      "(do,4)\n",
      "(completed,4)\n",
      "(simply,4)\n",
      "(relevant,4)\n",
      "(We,4)\n",
      "(credit,4)\n",
      "(Weekly,5)\n",
      "(Central,5)\n",
      "(quiz,5)\n",
      "(Machine,5)\n",
      "(new,5)\n",
      "(review,5)\n",
      "(grade,5)\n",
      "(data,5)\n",
      "(including,5)\n",
      "(at,5)\n",
      "(question,5)\n",
      "(concepts,5)\n",
      "(Monday,5)\n",
      "(only,5)\n",
      "(PM,5)\n",
      "(material,5)\n",
      "(one,6)\n",
      "(Each,6)\n",
      "(but,6)\n",
      "(use,6)\n",
      "(if,6)\n",
      "(This,6)\n",
      "(post,6)\n",
      "(may,6)\n",
      "(Learning|,6)\n",
      "(given,6)\n",
      "(quizzes,6)\n",
      "(Peer,6)\n",
      "(Moodle,7)\n",
      "(week.,7)\n",
      "(also,7)\n",
      "(from,8)\n",
      "(lesson,8)\n",
      "(peer,8)\n",
      "(pm,9)\n",
      "(students,9)\n",
      "(with,9)\n",
      "(Introduction,9)\n",
      "(have,9)\n",
      "(weekly,9)\n",
      "(not,9)\n",
      "(each,10)\n",
      "(can,10)\n",
      "(6:00,10)\n",
      "(You,10)\n",
      "(following,11)\n",
      "(or,11)\n",
      "(.,11)\n",
      "(assignments,11)\n",
      "(by,12)\n",
      "(instructor,12)\n",
      "(must,12)\n",
      "(as,13)\n",
      "(an,14)\n",
      "(points,15)\n",
      "(week,15)\n",
      "(The,16)\n",
      "(assignment,16)\n",
      "(we,17)\n",
      "(##,18)\n",
      "(are,19)\n",
      "(Week,22)\n",
      "(on,23)\n",
      "(your,23)\n",
      "(that,23)\n",
      "(is,24)\n",
      "(###,24)\n",
      "(this,24)\n",
      "(you,28)\n",
      "(in,29)\n",
      "(for,31)\n",
      "(course,31)\n",
      "(a,39)\n",
      "(be,39)\n",
      "(of,43)\n",
      "(and,48)\n",
      "(will,51)\n",
      "(to,55)\n",
      "(the,97)\n",
      "(|,116)\n",
      "2016-04-06 08:51:38,438 [main] INFO  org.apache.pig.Main - Pig script completed in 1 minute and 738 milliseconds (60738 ms)\n"
     ]
    }
   ],
   "source": [
    "!pig wordcount.pig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
